---
title: "downstreamGWAS"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

```{r setup}
library(downstreamGWAS)

```

downstreamGWAS has to ambition make standardized pipelines for downstream analysis that has genome-wide summary statistics as ***primary input***. Examples of these types of analysis are: gene-based tests (with magma or GCTA), or heritability enrichment (with S-LDSC). The required input for these analyses can typically be put into one of three categories:

(1) summary statistics

(2) reference data

(3) software dependencies

downstreamGWAS is aimed at making this painless and reproducible. Each part is tackled in the following way:

### (1) Summary statistics

downstreamGWAS relies on summary statistics first being cleaned by `tidyGWAS::tidyGWAS()`, and assumes that `output_format="hivestyle"` (the default argument), and that no changes has been made to the resulting folder structure.

With standardized column names and data formats, the functionality to prepare the summary statistics for the downstream analysis can be continously reused. For example, the [GCTB](https://cnsgenomics.com/software/gctb/#Overview) suite of genetic analysis uses the .ma format, and downstreamGWAS has defined method for converting tidyGWAS to .ma in `downstreamGWAS::to_ma()`. No need to write new code each time!

A common (and very time consuming step) is to first munge summary statistics, and prepare them with correct filters, column names and data-types. downstreamGWAS uses the standardized tidyGWAS output to automate this munging step, for example `downstreamGWAS::to_ma()` or `downstreamGWAS::to_ldsc()`.

### (2) Reference data

Another common issue is acquiring and using the same reference data for analysis. downstreamGWAS uses [Zenodo](https://zenodo.org) to host and share reference data where it is possible. This makes it easy to reproduce your results across computational clusters and research groups. See for example the reference files for running stratified LDscore regression [here](https://zenodo.org/records/8367200).

### (3) Software dependencies

Software can be difficult to install properly, especially when you are working on high performance clusters where you might not have enough permissions. To handle this, downstreamGWAS makes use of the software container [apptainer](https://apptainer.org). Apptainer can use [Docker](https://www.docker.com) images to produce a virtual environment, where sudo privileges are not required. For the downstream analysis implemented in downstreamGWAS, we have created docker images for each.

This virtualization also serves as another important factor in reproductibility, making sure analysis is conducted using the same underlying software.

## Setting up downstreamGWAS

To illustrate the results, we first create an toy example of a cleaned tidyGWAS sumstat.

```{r, include=FALSE}
sumstats <- tidyGWAS::test_file
outdir <- tempdir()
cleaned <- tidyGWAS(
  # Here we input the summary statistics as a data.frame already in R memory
  tbl = sumstats, 
  # provide the filepath to the refence files you downloaded.
  dbsnp_path = fs::path(fs::path_package("tidyGWAS"), "extdata/dbSNP155"),
  output_dir = fs::path(outdir, "example_gwas")
  )
```

Using only the filepath to output_folder, downstreamGWAS can generate a slurm script to run the specific downstream analysis. Here for example, a script to run [SbayesRC](https://github.com/zhilizheng/SBayesRC) is created, ready to run.

```{r}
downstreamGWAS::setup()
run_sldsc_cts(fs::path(outdir, "example_gwas"),cts_file = "toy.cts", write_script = FALSE)

```

# Setting up downstreamGWAS

```{r}
setup()
```
