[{"path":"http://arvidharder.com/downstreamGWAS/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 downstreamGWAS authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/agents.html","id":"id_-role--context","dir":"","previous_headings":"","what":"üß† Role & Context","title":"NA","text":"senior R developer specializing Tidyverse ecosystem. Always prioritize functional programming native pipe |>.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/agents.html","id":"id_-required-workflow","dir":"","previous_headings":"","what":"üõ† Required Workflow","title":"NA","text":"suggesting code changes, ensure can run: 1. devtools::load_all() - sync current changes. 2. devtools::document() - update documentation (NEVER edit man/*.Rd manually). 3. devtools::test() - verify unit tests pass.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/agents.html","id":"id_-style-guide","dir":"","previous_headings":"","what":"üìè Style Guide","title":"NA","text":"Use snake_case functions arguments. Use rlang non-standard evaluation (NSE) appropriate. Dependencies: Use pkg::fun() syntax; add library() calls R files.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/agents.html","id":"id_-repository-layout","dir":"","previous_headings":"","what":"üìÅ Repository Layout","title":"NA","text":"R/: R function logic. tests/testthat/: Unit tests. vignettes/: Use Rmd (.rmd) long-form documentation.","code":""},{"path":[]},{"path":"http://arvidharder.com/downstreamGWAS/agents.html","id":"writing-tests","dir":"","previous_headings":"üß™ Testing","what":"Writing Tests","title":"NA","text":"Unit tests (always run):","code":"test_that(\"basic validation works\", {   result <- some_function(data, dbsnp_path = dbsnp_path)  # uses fixture   expect_equal(...) })"},{"path":"http://arvidharder.com/downstreamGWAS/agents.html","id":"general-guidelines","dir":"","previous_headings":"üß™ Testing","what":"General Guidelines","title":"NA","text":"Write tests new functions features. Use testthat unit tests. Ensure tests cover edge cases typical use cases. Tests tests/testthat/ named test-<function>.R. Run tests devtools::test() committing changes. Use skip_if_no_full_dbsnp() tests require full reference data. Never use unconditional skip() - always provide condition reason.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"downstreamGWAS","text":"downstreamGWAS ambition make standardized pipelines downstream analysis genome-wide summary statistics primary input. Examples types analysis : gene-based tests (magma GCTA), heritability enrichment (S-LDSC). required input analyses can typically put one three categories: summary statistics reference data software dependencies downstreamGWAS aimed making painless reproducible. part tackled following way:","code":"library(downstreamGWAS) library(fs) library(tidyGWAS)"},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"summary-statistics","dir":"Articles","previous_headings":"Introduction","what":"(1) Summary statistics","title":"downstreamGWAS","text":"downstreamGWAS relies summary statistics first cleaned tidyGWAS::tidyGWAS(), assumes output_format=\"hivestyle\" (default argument), changes made resulting folder structure. standardized column names data formats, functionality prepare summary statistics downstream analysis can continously reused. example, GCTB suite genetic analysis uses .ma format, downstreamGWAS defined method converting tidyGWAS .ma downstreamGWAS::to_ma(). need write new code time! common (time consuming step) first munge summary statistics, prepare correct filters, column names data-types. downstreamGWAS uses standardized tidyGWAS output automate munging step, example downstreamGWAS::to_ma() downstreamGWAS::to_ldsc().","code":""},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"reference-data","dir":"Articles","previous_headings":"Introduction","what":"(2) Reference data","title":"downstreamGWAS","text":"Another common issue acquiring using reference data analysis. downstreamGWAS uses Zenodo host share reference data possible. makes easy reproduce results across computational clusters research groups. See example reference files running stratified LDscore regression .","code":""},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"software-dependencies","dir":"Articles","previous_headings":"Introduction","what":"(3) Software dependencies","title":"downstreamGWAS","text":"Software can difficult install properly, especially working high performance clusters might enough permissions. handle , downstreamGWAS makes use software container apptainer. Apptainer can use Docker images produce virtual environment, sudo privileges required. downstream analysis implemented downstreamGWAS, created docker images . virtualization also serves another important factor reproductibility, making sure analysis conducted using underlying software.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"setting-up-downstreamgwas","dir":"Articles","previous_headings":"Introduction","what":"Setting up downstreamGWAS","title":"downstreamGWAS","text":"illustrate results, first create toy example cleaned tidyGWAS sumstat. Using filepath output_folder, downstreamGWAS can generate slurm script run specific downstream analysis. example, script run SbayesRC created, ready run.","code":"sumstats <- tidyGWAS::test_file outdir <- tempdir() cleaned <- tidyGWAS(   # Here we input the summary statistics as a data.frame already in R memory   tbl = sumstats,    # provide the filepath to the refence files you downloaded.   dbsnp_path = path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\"),   output_dir = path(outdir, \"example_gwas\")   )"},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"running-sbayesrc","dir":"Articles","previous_headings":"Introduction > Setting up downstreamGWAS","what":"Running SbayesRC","title":"downstreamGWAS","text":"","code":"# downstreamGWAS uses the \"HOME\" variable to store data on where you keep the reference files between sessions.  withr::local_envvar(list(\"HOME\" = tempdir())) dsg_folder <- fs::path(tempdir(), \"downstreamGWAS_folder\") # use setup to tell downstreamGWAS where the reference data and containers are kept # only has to be done once setup(dsg_folder) run_sbayesrc(fs::path(outdir, \"example_gwas\"),  write_script = FALSE)"},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"cell-type-analysis-using-s-ldsc","dir":"Articles","previous_headings":"Introduction > Setting up downstreamGWAS","what":"cell-type analysis using S-LDSC","title":"downstreamGWAS","text":"","code":"run_sldsc_cts(fs::path(outdir, \"example_gwas\"),cts_file = \"toy.cts\", write_script = FALSE)"},{"path":"http://arvidharder.com/downstreamGWAS/articles/downstreamGWAS.html","id":"setting-up-downstreamgwas-1","dir":"Articles","previous_headings":"","what":"Setting up downstreamGWAS","title":"downstreamGWAS","text":"WORK PROGRESS","code":""},{"path":"http://arvidharder.com/downstreamGWAS/articles/meta-analysis.html","id":"meta-analysis","dir":"Articles","previous_headings":"","what":"Meta-analysis","title":"meta-analysis","text":"downstreamGWAS implemented inverse-variance-weighted fixed-effects meta-analysis equal ‚ÄúStdErr‚Äù metal. Sample-size weighted meta-analysis yet implemented, planned feature. illustrate downstreamGWAS::meta_analyze() function, utilize summary statistics repository local HPC cluster (128 summary statistics). summary statistic cleaned can combined multi-dataset creating symlink tidyGWAS_hivestyle folder summary statistic. format looks like.","code":"multi_dataset <- function(dir, new_dir) {   symlink <- dplyr::tibble(     basedir = fs::dir_ls(dir),     old_path = fs::path(basedir, \"tidyGWAS_hivestyle\"),     dataset_name = fs::path_file(basedir),     new_path = fs::path(new_dir, paste0(\"dataset_name=\", dataset_name))   ) |>      dplyr::select(old_path, new_path)      fs::link_create(symlink$old_path, symlink$new_path) } fs::dir_create(\"/work/users/a/r/arvhar/multi_dataset\") multi_dataset(\"/work/users/a/r/arvhar/tidyGWAS_stuff/output2\", \"/work/users/a/r/arvhar/multi_dataset\")  dir_ls(\"/work/users/a/r/arvhar/multi_dataset\") |>    head()"},{"path":"http://arvidharder.com/downstreamGWAS/articles/meta-analysis.html","id":"working-with-a-multi-dataset","dir":"Articles","previous_headings":"Meta-analysis","what":"Working with a multi-dataset","title":"meta-analysis","text":"‚Äôs useful read arrow interacts dplyr next part. can open multi-dataset arrow::open_dataset(). can use standard dplyr commands like dplyr::filter() dplyr::select(). example, let‚Äôs meta-analyze three waves schizophrenia GWASes (Even though nonsensical). Meta-analyzing three summary statistics took 70 seconds, meta-analyzing 76 summary statistics took ~15 minutes compute cluster 3 cores 25gb memory. CaseN, ControlN INFO kept exist input summary statistics.","code":"ds <- arrow::open_dataset(\"/work/users/a/r/arvhar/multi_dataset\")  sumstats <- ds |>    dplyr::filter(dataset_name %in% c(\"scz2014\",\"scz2018_clozuk\", \"scz2022\")) tic(\"Meta-analyze three traits for chromosome 1\") res <- ds |>    dplyr::filter(dataset_name %in% c(\"scz2014\",\"scz2018_clozuk\", \"scz2022\")) |>    downstreamGWAS::meta_analyze(by = c(\"CHR\", \"POS\", \"EffectAllele\",\"OtherAllele\", \"RSID\")) toc()"},{"path":"http://arvidharder.com/downstreamGWAS/articles/multi-file-datasets.html","id":"combining-cleaned-summary-statistics","dir":"Articles","previous_headings":"","what":"Combining cleaned summary statistics","title":"multi-file datasets","text":"Let‚Äôs pretend cleaned 3 different summary statistics. seems natural put place, whenever want work summary statistics, can ones already cleaned. cleaned_GWAS` folder, now three folders corresponding three traits. cleaned summary statistics divided chromosome. turn useful apply hivestyle partition - level traits. recommended method use symbolic links create next level mapping. way cleaning separated. creating symbolic links trait name hivestyle format, ‚Äôve created multi-file dataset level traits. Queries can now built across multiple summary statistics using normal dplyr syntax. Without calling dplyr::collect(), query executed. Rather, planned query displayed. complex queries can built: example, querying specific region can extremely fast. Across test collection 241 summary statistics, command took ~8 seconds using just 2 cores. beautiful thing seamless integration dplyr. types queries can written normal dplyr code, transformed highly efficient arrow c++ code. work just single trait, just traits. Tip: can take lot time read 20 columns. Since parquet files stored columnar storage, overhead reading subset columns","code":"gwas_repository <- fs::path(tempdir(), \"cleaned_GWAS\") for(i in c(\"trait1\", \"trait2\", \"trait3\")) {   out <- fs::path(gwas_repository, i)   print(paste0(\"Cleaning \", i, \"and saving results to: \", out))   tidyGWAS(    tbl = test_file,    dbsnp_path = fs::path(fs::path_package(\"tidyGWAS\"), \"extdata/dbSNP155\"),    output_dir = out   ) } dir_tree(gwas_repository, recurse = 1) dir_tree(fs::path(gwas_repository, \"trait3\", \"tidyGWAS_hivestyle\")) symlinks <- path(tempdir(), \"arrow_traits\")  # identify the filepath to all cleaned summary statistics sumstats_path <- dir_ls(gwas_repository, glob = \"*tidyGWAS_hivestyle\", recurse = 1)  # for each sumstat, we can get the trait name by considering the parent directory name names <- path_file(path_dir(sumstats_path)) symlinked_path <- path(symlinks, paste0(\"dataset_name=\", names))  # create the directory where we create the symbolic links dir_create(symlinks) link_create(sumstats_path, symlinked_path)  dir_tree(symlinks) ds <- arrow::open_dataset(symlinks) ds ds |>    dplyr::filter(P < 5e-08) ds |>    filter(P < 5e-08) |>    collect() |>    summarise(n = n()) ds |>    # group by each summary statistic   group_by(dataset_name, CHR) |>    filter(P < 5e-08) |>    summarise(n_sig_variants_per_trait = n()) |>    collect() |>    head() all_sig <- ds |>    # CHR 7 POS >= 1788081 & POS <= 2289862 is one of the top significant loci   # in schizophrenia.   dplyr::filter(CHR == \"7\") |>    dplyr::filter(POS >= 1788081 & POS <= 2289862) |>    dplyr::filter(P < 5e-08) |>    dplyr::select(RSID, P, B, SE, dataset_name) |>    dplyr::collect() sumstats <- ds |>    filter(dataset_name %in% c(\"trait1\", \"trait2\")) |>    # addin this line will is much quicker to read in the data to memory   select(dataset_name, RSID, EffectAllele, OtherAlllele, EAF, B, SE, P, N) |>    collect()"},{"path":"http://arvidharder.com/downstreamGWAS/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"package maintainer. Maintainer.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Harder (2026). downstreamGWAS: Standardized downstream pipelines GWAS. R package version 0.2.0, http://arvidharder.com/downstreamGWAS/.","code":"@Manual{,   title = {downstreamGWAS: Standardized downstream pipelines for GWAS},   author = {Arvid Harder},   year = {2026},   note = {R package version 0.2.0},   url = {http://arvidharder.com/downstreamGWAS/}, }"},{"path":"http://arvidharder.com/downstreamGWAS/index.html","id":"downstreamgwas","dir":"","previous_headings":"","what":"Standardized downstream pipelines for GWAS","title":"Standardized downstream pipelines for GWAS","text":"downstreamGWAS companion package tidyGWAS. downstreamGWAS provides functions run standardize genetic pipelines using summary statistics input. External software packaged docker files available dockerhub. addition , reference files needed pipelines bundled containers available zenodo. Link TBD. DownstreamGWAS utilises three factors make genetic analysis much simplified: 1. Harmonized GWAS format tidyGWAS 2. External software packaged docker images, can run HPCs singularity/apptainer 3. References files collected available download, harmonized filepaths","code":""},{"path":"http://arvidharder.com/downstreamGWAS/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Standardized downstream pipelines for GWAS","text":"downstreamGWAS requires filepaths.yml file created, add information . ```{r} dir_to_store_yaml_in = ‚Äú/nas/depts/007/sullilab/shared/gwas_sumstats‚Äù setup_filepaths_yml(dir_to_store_yaml_in) # get script download singularity images sif_script() ```","code":"remotes::install_github(\"ararder/downstreamGWAS\") devtools::install_github(\"ararder/downstreamGWAS\")"},{"path":[]},{"path":"http://arvidharder.com/downstreamGWAS/reference/check_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that the configuration file has been correctly set up ‚Äî check_setup","title":"Check that the configuration file has been correctly set up ‚Äî check_setup","text":"Check configuration file correctly set ","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/check_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that the configuration file has been correctly set up ‚Äî check_setup","text":"","code":"check_setup()"},{"path":"http://arvidharder.com/downstreamGWAS/reference/check_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that the configuration file has been correctly set up ‚Äî check_setup","text":"text terminal","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/check_setup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check that the configuration file has been correctly set up ‚Äî check_setup","text":"","code":"if (FALSE) { # \\dontrun{ check_setup() } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/downstreamGWAS-package.html","id":null,"dir":"Reference","previous_headings":"","what":"downstreamGWAS: Standardized downstream pipelines for GWAS ‚Äî downstreamGWAS-package","title":"downstreamGWAS: Standardized downstream pipelines for GWAS ‚Äî downstreamGWAS-package","text":"Standardized analysis genome-wide summary statistics.","code":""},{"path":[]},{"path":"http://arvidharder.com/downstreamGWAS/reference/dsg_method_output_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Resolve downstreamGWAS pipeline output directory ‚Äî dsg_method_output_dir","title":"Resolve downstreamGWAS pipeline output directory ‚Äî dsg_method_output_dir","text":"Resolve downstreamGWAS pipeline output directory","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/dsg_method_output_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resolve downstreamGWAS pipeline output directory ‚Äî dsg_method_output_dir","text":"","code":"dsg_method_output_dir(parent_dir, method_name, output_dir = NULL)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/dsg_method_output_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resolve downstreamGWAS pipeline output directory ‚Äî dsg_method_output_dir","text":"parent_dir Path tidyGWAS::tidyGWAS() output directory. method_name Method identifier, e.g. clumping. output_dir Optional custom output directory.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/dsg_method_output_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resolve downstreamGWAS pipeline output directory ‚Äî dsg_method_output_dir","text":"Absolute path output directory.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/effective_n.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate effective N ‚Äî effective_n","title":"Calculate effective N ‚Äî effective_n","text":"Calculate effective N","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/effective_n.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate effective N ‚Äî effective_n","text":"","code":"effective_n(cases, controls)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/effective_n.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate effective N ‚Äî effective_n","text":"cases Number cases controls Number controls","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/effective_n.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate effective N ‚Äî effective_n","text":"numeric value","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/effective_n.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate effective N ‚Äî effective_n","text":"","code":"effective_n(1000, 3000) #> [1] 3000"},{"path":"http://arvidharder.com/downstreamGWAS/reference/format_coloc.html","id":null,"dir":"Reference","previous_headings":"","what":"Format the output of coloc::coloc.abf() ‚Äî format_coloc","title":"Format the output of coloc::coloc.abf() ‚Äî format_coloc","text":"Format output coloc::coloc.abf()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/format_coloc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format the output of coloc::coloc.abf() ‚Äî format_coloc","text":"","code":"format_coloc(coloc_obj, name)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/format_coloc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format the output of coloc::coloc.abf() ‚Äî format_coloc","text":"coloc_obj output coloc call name name trait","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/format_coloc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format the output of coloc::coloc.abf() ‚Äî format_coloc","text":"dplyr::tibble()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/format_coloc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format the output of coloc::coloc.abf() ‚Äî format_coloc","text":"","code":"if (FALSE) { # \\dontrun{ format_coloc(ob, \"test-run\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/get_system_paths.html","id":null,"dir":"Reference","previous_headings":"","what":"Read downstreamGWAS filepaths from yaml file downstreamGWAS manages external filepaths through two files: ‚Äî get_system_paths","title":"Read downstreamGWAS filepaths from yaml file downstreamGWAS manages external filepaths through two files: ‚Äî get_system_paths","text":"param.yml file contains filepaths reference data software containers filepaths start reference/ containers/ respectively. param.yml file bundled downstreamGWAS package.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/get_system_paths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read downstreamGWAS filepaths from yaml file downstreamGWAS manages external filepaths through two files: ‚Äî get_system_paths","text":"","code":"get_system_paths()"},{"path":"http://arvidharder.com/downstreamGWAS/reference/get_system_paths.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read downstreamGWAS filepaths from yaml file downstreamGWAS manages external filepaths through two files: ‚Äî get_system_paths","text":"nested list filepaths","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/get_system_paths.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read downstreamGWAS filepaths from yaml file downstreamGWAS manages external filepaths through two files: ‚Äî get_system_paths","text":"Secondly, config.yml file contains local configuaration paramerers, path downstreamGWAS data folder, call apptainer/singularity. config.yml file needs setup locally.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/get_system_paths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read downstreamGWAS filepaths from yaml file downstreamGWAS manages external filepaths through two files: ‚Äî get_system_paths","text":"","code":"if (FALSE) { # \\dontrun{ get_system_paths() } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/liability_scale_h2.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an estiamte of observed-scale heritability to liability scale heritability ‚Äî liability_scale_h2","title":"Convert an estiamte of observed-scale heritability to liability scale heritability ‚Äî liability_scale_h2","text":"Convert estiamte observed-scale heritability liability scale heritability","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/liability_scale_h2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an estiamte of observed-scale heritability to liability scale heritability ‚Äî liability_scale_h2","text":"","code":"liability_scale_h2(obs_h2, pop_prev, sample_prev = 0.5)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/liability_scale_h2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an estiamte of observed-scale heritability to liability scale heritability ‚Äî liability_scale_h2","text":"obs_h2 observed-scale heritability pop_prev prevalence disorder general population sample_prev prevalence disorder sample. Default value 0.5, reflecting case-control study using effective N sample size","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/liability_scale_h2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an estiamte of observed-scale heritability to liability scale heritability ‚Äî liability_scale_h2","text":"double","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/liability_scale_h2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert an estiamte of observed-scale heritability to liability scale heritability ‚Äî liability_scale_h2","text":"","code":"liability_scale_h2(0.25, 0.02) #> [1] 0.1638687"},{"path":"http://arvidharder.com/downstreamGWAS/reference/ls_sumstats.html","id":null,"dir":"Reference","previous_headings":"","what":"List the available sumstats ‚Äî ls_sumstats","title":"List the available sumstats ‚Äî ls_sumstats","text":"List available sumstats","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/ls_sumstats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List the available sumstats ‚Äî ls_sumstats","text":"","code":"ls_sumstats(folder = NULL)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/ls_sumstats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List the available sumstats ‚Äî ls_sumstats","text":"folder can used specify summary statistics . Default value NULL, sumstats_folder parameter used config.yaml file","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/ls_sumstats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List the available sumstats ‚Äî ls_sumstats","text":"dplyr::tibble()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/ls_sumstats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List the available sumstats ‚Äî ls_sumstats","text":"","code":"if (FALSE) { # \\dontrun{ ls_sumstats() } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/mr_on_tidyGWAS.html","id":null,"dir":"Reference","previous_headings":"","what":"Run two-sample mendelian randomisation using the TwoSampleMR package ‚Äî mr_on_tidyGWAS","title":"Run two-sample mendelian randomisation using the TwoSampleMR package ‚Äî mr_on_tidyGWAS","text":"Run two-sample mendelian randomisation using TwoSampleMR package","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/mr_on_tidyGWAS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run two-sample mendelian randomisation using the TwoSampleMR package ‚Äî mr_on_tidyGWAS","text":"","code":"mr_on_tidyGWAS(   exposure_dir,   outcome_dir,   exposure_bed = NULL,   bidirectional = FALSE,   r2 = 0.01 )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/mr_on_tidyGWAS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run two-sample mendelian randomisation using the TwoSampleMR package ‚Äî mr_on_tidyGWAS","text":"exposure_dir path tidyGWAS directory exposure outcome_dir path tidyGWAS directory outcome exposure_bed Use custom bed file define lead SNPs? Default NULL, downstreamGWAS run run_clumping() bed file exists. bidirectional run outcome exposure exposure outcome well? r2 r2 pass plink2 clumping","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/mr_on_tidyGWAS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run two-sample mendelian randomisation using the TwoSampleMR package ‚Äî mr_on_tidyGWAS","text":"list","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/mr_on_tidyGWAS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run two-sample mendelian randomisation using the TwoSampleMR package ‚Äî mr_on_tidyGWAS","text":"","code":"if (FALSE) { # \\dontrun{ mr_on_tidyGWAS(\"exp_dir/trait1\", \"outcomes/trait2\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_clumping.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipeline clumping ‚Äî pipeline_clumping","title":"Pipeline clumping ‚Äî pipeline_clumping","text":"Pipeline clumping","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_clumping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipeline clumping ‚Äî pipeline_clumping","text":"","code":"pipeline_clumping(   parent_dir,   output_dir = NULL,   write_script = TRUE,   execute = FALSE,   p1 = \"5e-08\",   p2 = \"5e-06\",   r2 = 0.1,   kb = 3000,   schedule = NULL,   prepare_inputs = execute,   check_paths = TRUE )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_clumping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipeline clumping ‚Äî pipeline_clumping","text":"parent_dir Path tidyGWAS::tidyGWAS() output directory. output_dir Optional custom output directory. Defaults <parent_dir>/analysis/clumping. write_script script written disk? execute generated script executed via system2(\"bash\", ...)? p1 Passed PLINK --clump-p1. p2 Passed PLINK --clump-p2. r2 Passed PLINK --clump-r2. kb Passed PLINK --clump-kb. schedule Optional schedule object (e.g. schedule_slurm()). NULL, scheduler header written local bash execution used. prepare_inputs input preparation step (e.g. to_ma(), to_clumping()) included generated script? Defaults execute. check_paths required files directories validated execution/submission? Defaults TRUE.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_clumping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipeline clumping ‚Äî pipeline_clumping","text":"list script metadata.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayesrc.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipeline SBayesRC ‚Äî pipeline_sbayesrc","title":"Pipeline SBayesRC ‚Äî pipeline_sbayesrc","text":"Pipeline SBayesRC","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayesrc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipeline SBayesRC ‚Äî pipeline_sbayesrc","text":"","code":"pipeline_sbayesrc(   parent_dir,   output_dir = NULL,   write_script = TRUE,   execute = FALSE,   thread_rc = 8,   thread_imp = 4,   use_effective_n = FALSE,   schedule = NULL,   prepare_inputs = execute,   check_paths = TRUE )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayesrc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipeline SBayesRC ‚Äî pipeline_sbayesrc","text":"parent_dir Path tidyGWAS::tidyGWAS() output directory. output_dir Optional custom output directory. Defaults <parent_dir>/analysis/sbayesrc. write_script script written disk? execute generated script executed via system2(\"bash\", ...)? thread_rc Number OMP threads SBayesRC::sbayesrc. thread_imp Number OMP threads SBayesRC::impute. use_effective_n Passed to_ma(). schedule Optional schedule object (e.g. schedule_slurm()). NULL, scheduler header written local bash execution used. prepare_inputs input preparation step (e.g. to_ma(), to_clumping()) included generated script? Defaults execute. check_paths required files directories validated execution/submission? Defaults TRUE.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayesrc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipeline SBayesRC ‚Äî pipeline_sbayesrc","text":"list script metadata.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayess.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipeline SBayesS ‚Äî pipeline_sbayess","title":"Pipeline SBayesS ‚Äî pipeline_sbayess","text":"Pipeline SBayesS","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipeline SBayesS ‚Äî pipeline_sbayess","text":"","code":"pipeline_sbayess(   parent_dir,   output_dir = NULL,   write_script = TRUE,   execute = FALSE,   pi = \"0.01\",   hsq = \"0.5\",   num_chains = \"4\",   chain_length = \"25000\",   burn_in = \"5000\",   seed = \"2023\",   thread = \"8\",   use_effective_n = FALSE,   schedule = NULL,   prepare_inputs = execute,   check_paths = TRUE )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipeline SBayesS ‚Äî pipeline_sbayess","text":"parent_dir Path tidyGWAS::tidyGWAS() output directory. output_dir Optional custom output directory. Defaults <parent_dir>/analysis/sbayess. write_script script written disk? execute generated script executed via system2(\"bash\", ...)? pi Passed GCTB --pi. hsq Passed GCTB --hsq. num_chains Passed GCTB --num-chains. chain_length Passed GCTB --chain-length. burn_in Passed GCTB --burn-. seed Passed GCTB --seed. thread Passed GCTB --thread. use_effective_n Passed to_ma(). schedule Optional schedule object (e.g. schedule_slurm()). NULL, scheduler header written local bash execution used. prepare_inputs input preparation step (e.g. to_ma(), to_clumping()) included generated script? Defaults execute. check_paths required files directories validated execution/submission? Defaults TRUE.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/pipeline_sbayess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipeline SBayesS ‚Äî pipeline_sbayess","text":"list script metadata.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/ranges_to_bed.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert the output of plink clumping ranges to a flat file ‚Äî ranges_to_bed","title":"Convert the output of plink clumping ranges to a flat file ‚Äî ranges_to_bed","text":"Convert output plink clumping ranges flat file","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/ranges_to_bed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert the output of plink clumping ranges to a flat file ‚Äî ranges_to_bed","text":"","code":"ranges_to_bed(clump_dir)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/ranges_to_bed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert the output of plink clumping ranges to a flat file ‚Äî ranges_to_bed","text":"clump_dir directory plink clumping output stored","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/ranges_to_bed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert the output of plink clumping ranges to a flat file ‚Äî ranges_to_bed","text":"","code":"if (FALSE) { # \\dontrun{ ranges_to_bed(\"/path/to/clumping/dir\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_gwas.html","id":null,"dir":"Reference","previous_headings":"","what":"Read in a tidyGWAS formatted summary statistics file ‚Äî read_gwas","title":"Read in a tidyGWAS formatted summary statistics file ‚Äî read_gwas","text":"Read tidyGWAS formatted summary statistics file","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_gwas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read in a tidyGWAS formatted summary statistics file ‚Äî read_gwas","text":"","code":"read_gwas(parent_folder, columns)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_gwas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read in a tidyGWAS formatted summary statistics file ‚Äî read_gwas","text":"parent_folder filepath parent_folder tidyGWAS_hivestyle columns character vector columns names, passed dplyr::select(dplyr::any_of(columns))","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_gwas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read in a tidyGWAS formatted summary statistics file ‚Äî read_gwas","text":"data.frame()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_gwas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read in a tidyGWAS formatted summary statistics file ‚Äî read_gwas","text":"","code":"if (FALSE) { # \\dontrun{ read_gwas(\"/tidyGWAS_files/mdd2019\") # or if you have saved the summary statistics filepath in the config.yaml file # see [tidyGWAS_paths()] read_gwas(\"mdd2019\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_ldsc_h2.html","id":null,"dir":"Reference","previous_headings":"","what":"read the output of LDSC ‚Äìh2 ‚Äî read_ldsc_h2","title":"read the output of LDSC ‚Äìh2 ‚Äî read_ldsc_h2","text":"read output LDSC ‚Äìh2","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_ldsc_h2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read the output of LDSC ‚Äìh2 ‚Äî read_ldsc_h2","text":"","code":"read_ldsc_h2(path)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_ldsc_h2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read the output of LDSC ‚Äìh2 ‚Äî read_ldsc_h2","text":"path log file","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_ldsc_h2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"read the output of LDSC ‚Äìh2 ‚Äî read_ldsc_h2","text":"tibble","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/read_ldsc_h2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"read the output of LDSC ‚Äìh2 ‚Äî read_ldsc_h2","text":"","code":"if (FALSE) { # \\dontrun{ parse_ldsc_h2(\"ldsc_h2.log\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_clumping.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a clumping pipeline on a tidyGWAS sumstats ‚Äî run_clumping","title":"Run a clumping pipeline on a tidyGWAS sumstats ‚Äî run_clumping","text":"Run clumping pipeline tidyGWAS sumstats","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_clumping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a clumping pipeline on a tidyGWAS sumstats ‚Äî run_clumping","text":"","code":"run_clumping(path, output_dir = NULL, ...)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_clumping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a clumping pipeline on a tidyGWAS sumstats ‚Äî run_clumping","text":"path filepath tidyGWAS folder output_dir directory write clumping results ... arguments pass plink2 call","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_clumping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a clumping pipeline on a tidyGWAS sumstats ‚Äî run_clumping","text":"bed file clumps","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_clumping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a clumping pipeline on a tidyGWAS sumstats ‚Äî run_clumping","text":"","code":"if (FALSE) { # \\dontrun{ ranges_to_bed(\"/path/to/tidyGWAS\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_coloc.html","id":null,"dir":"Reference","previous_headings":"","what":"Run coloc::coloc.abf on tidyGWAS data ‚Äî run_coloc","title":"Run coloc::coloc.abf on tidyGWAS data ‚Äî run_coloc","text":"Run coloc::coloc.abf tidyGWAS data","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_coloc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run coloc::coloc.abf on tidyGWAS data ‚Äî run_coloc","text":"","code":"run_coloc(   parent_dir,   parent_dir2,   chr,   start,   end,   min_pval = 5e-08,   trait_type1 = c(\"guess\", \"cc\", \"quant\"),   trait_type2 = c(\"guess\", \"cc\", \"quant\"),   p1 = 1e-04,   p2 = 1e-04,   p12 = 1e-05 )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_coloc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run coloc::coloc.abf on tidyGWAS data ‚Äî run_coloc","text":"parent_dir tidyGWAS directory GWAS parent_dir2 tidyGWAS directory GWAS chr chromosome start start region end end region min_pval minimum pval required proceed coloc trait2 trait_type1 quantitative case-control? trait_type2 quantitative case-control? p1 prior colof.abf p2 prior colof.abf p12 prior colof.abf","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_coloc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run coloc::coloc.abf on tidyGWAS data ‚Äî run_coloc","text":"output coloc::coloc.abf()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_coloc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run coloc::coloc.abf on tidyGWAS data ‚Äî run_coloc","text":"","code":"if (FALSE) { # \\dontrun{ run_coloc(\"path/trait1\", \"path/trait2\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_mbat_combo.html","id":null,"dir":"Reference","previous_headings":"","what":"run mBAT-combo gene-test in GCTB ‚Äî run_mbat_combo","title":"run mBAT-combo gene-test in GCTB ‚Äî run_mbat_combo","text":"run mBAT-combo gene-test GCTB","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_mbat_combo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"run mBAT-combo gene-test in GCTB ‚Äî run_mbat_combo","text":"","code":"run_mbat_combo(   parent_folder,   ...,   write_script = TRUE,   outfolder = NULL,   thread_num = 10 )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_mbat_combo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"run mBAT-combo gene-test in GCTB ‚Äî run_mbat_combo","text":"parent_folder filepath tidyGWAS folder ... arguments slurm write_script code written disk? outfolder write output thread_num number threads use","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_mbat_combo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"run mBAT-combo gene-test in GCTB ‚Äî run_mbat_combo","text":"character vector script filepath","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_mbat_combo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"run mBAT-combo gene-test in GCTB ‚Äî run_mbat_combo","text":"","code":"if (FALSE) { # \\dontrun{ mbat_combo(\"path_to_tidyGWAS/folder/sumstat1\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayesrc.html","id":null,"dir":"Reference","previous_headings":"","what":"Run sbayerc with tidyGWAS structure ‚Äî run_sbayesrc","title":"Run sbayerc with tidyGWAS structure ‚Äî run_sbayesrc","text":"Run sbayerc tidyGWAS structure","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayesrc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run sbayerc with tidyGWAS structure ‚Äî run_sbayesrc","text":"","code":"run_sbayesrc(   parent_folder,   ...,   write_script = TRUE,   thread_rc = 8,   thread_imp = 4,   use_effective_n = FALSE,   repair_EAF = NULL )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayesrc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run sbayerc with tidyGWAS structure ‚Äî run_sbayesrc","text":"parent_folder path tidyGWAS folder ... pass arguments slurm_header() write_script script written file disk? thread_rc threads rescaling thread_imp threads imputing use_effective_n attempt made calculate effective N repair_EAF EAF repaired? , provide path file columns RSID, EffectAllele, OtherAllele, EAF","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayesrc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run sbayerc with tidyGWAS structure ‚Äî run_sbayesrc","text":"filepath character vector","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayesrc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run sbayerc with tidyGWAS structure ‚Äî run_sbayesrc","text":"","code":"if (FALSE) { # \\dontrun{ run_sbayesrc() } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Sbayes-S with tidyGWAS structure ‚Äî run_sbayess","title":"Run Sbayes-S with tidyGWAS structure ‚Äî run_sbayess","text":"Run Sbayes-S tidyGWAS structure","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Sbayes-S with tidyGWAS structure ‚Äî run_sbayess","text":"","code":"run_sbayess(   parent_folder,   ...,   write_script = TRUE,   pi = \"0.01\",   hsq = \"0.5\",   num_chains = \"4\",   chain_length = \"25000\",   burn_in = \"5000\",   seed = \"2023\",   thread = \"8\" )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Sbayes-S with tidyGWAS structure ‚Äî run_sbayess","text":"parent_folder filepath tidyGWAS::tidyGWAS() folder ... pass arguments slurm_header() write_script captured code written disk .sh file? pi argument passed sbayes hsq argument passed sbayes num_chains argument passed sbayes chain_length argument passed sbayes burn_in argument passed sbayes seed argument passed sbayes thread argument passed sbayes","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Sbayes-S with tidyGWAS structure ‚Äî run_sbayess","text":"filepath character vector","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Sbayes-S with tidyGWAS structure ‚Äî run_sbayess","text":"","code":"if (FALSE) { # \\dontrun{ run_sbayess() } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess_req.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if required files exist for Sbayes-S ‚Äî run_sbayess_req","title":"Check if required files exist for Sbayes-S ‚Äî run_sbayess_req","text":"Check required files exist Sbayes-S","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess_req.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if required files exist for Sbayes-S ‚Äî run_sbayess_req","text":"","code":"run_sbayess_req()"},{"path":"http://arvidharder.com/downstreamGWAS/reference/run_sbayess_req.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if required files exist for Sbayes-S ‚Äî run_sbayess_req","text":"","code":"if (FALSE) { # \\dontrun{ run_sbayess_req() } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/schedule_slurm.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a SLURM schedule object ‚Äî schedule_slurm","title":"Construct a SLURM schedule object ‚Äî schedule_slurm","text":"Construct SLURM schedule object","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/schedule_slurm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a SLURM schedule object ‚Äî schedule_slurm","text":"","code":"schedule_slurm(   time = \"24:00:00\",   mem = \"8gb\",   cpus_per_task = NULL,   account = NULL,   partition = NULL )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/schedule_slurm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a SLURM schedule object ‚Äî schedule_slurm","text":"time SLURM time limit. mem SLURM memory request. cpus_per_task SLURM CPUs per task. account Optional SLURM account. partition Optional SLURM partition.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/schedule_slurm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a SLURM schedule object ‚Äî schedule_slurm","text":"schedule object can passed pipeline_*() functions.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup required filepaths for downstreamGWAS ‚Äî setup","title":"Setup required filepaths for downstreamGWAS ‚Äî setup","text":"Setup required filepaths downstreamGWAS","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup required filepaths for downstreamGWAS ‚Äî setup","text":"","code":"setup(   downstreamGWAS_folder,   container_dependency = \"\",   container_software = c(\"apptainer\", \"singularity\") )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup required filepaths for downstreamGWAS ‚Äî setup","text":"downstreamGWAS_folder Local filepath downstreamGWAS data stored container_dependency need load singularity/apptainer HPC? example: \"ml apptainer\" container_software container software use? \"apptainer\" \"singularity\"","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setup required filepaths for downstreamGWAS ‚Äî setup","text":"","code":"if (FALSE) { # \\dontrun{ setup() } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup_dsg.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup downstreamGWAS config ‚Äî setup_dsg","title":"Setup downstreamGWAS config ‚Äî setup_dsg","text":"Setup downstreamGWAS config","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup_dsg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup downstreamGWAS config ‚Äî setup_dsg","text":"","code":"setup_dsg(   storage_root,   sumstats_folder = NULL,   container_dependency = \"\",   force = FALSE )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup_dsg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup downstreamGWAS config ‚Äî setup_dsg","text":"storage_root Long-term storage root references containers. sumstats_folder Optional default folder containing tidyGWAS datasets. container_dependency Optional shell command load runtime dependencies HPC (e.g. \"ml apptainer\"). force Overwrite existing config file?","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/setup_dsg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup downstreamGWAS config ‚Äî setup_dsg","text":"Path written config file.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/slurm_header.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a slurm header ‚Äî slurm_header","title":"Construct a slurm header ‚Äî slurm_header","text":"Construct slurm header","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/slurm_header.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a slurm header ‚Äî slurm_header","text":"","code":"slurm_header(   time = \"24:00:00\",   mem = \"8gb\",   output = NULL,   account = NULL,   partition = NULL,   cpus_per_task = NULL )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/slurm_header.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a slurm header ‚Äî slurm_header","text":"time time allocated job mem memory allocated job (remember use 'gb' ending) output filepath output slurm log file account account partition partition cpus_per_task cpus per task","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/slurm_header.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a slurm header ‚Äî slurm_header","text":"character vector slurm header","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/slurm_header.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a slurm header ‚Äî slurm_header","text":"","code":"slurm_header() #> [1] \"#!/bin/bash\"             \"#SBATCH --mem=8gb\"       #> [3] \"#SBATCH --time=24:00:00\""},{"path":"http://arvidharder.com/downstreamGWAS/reference/tidyGWAS_paths.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the folder structure and filepaths for downstreamGWAS directory ‚Äî tidyGWAS_paths","title":"Create the folder structure and filepaths for downstreamGWAS directory ‚Äî tidyGWAS_paths","text":"Create folder structure filepaths downstreamGWAS directory","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/tidyGWAS_paths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the folder structure and filepaths for downstreamGWAS directory ‚Äî tidyGWAS_paths","text":"","code":"tidyGWAS_paths(dir)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/tidyGWAS_paths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the folder structure and filepaths for downstreamGWAS directory ‚Äî tidyGWAS_paths","text":"dir filepath folder","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/tidyGWAS_paths.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the folder structure and filepaths for downstreamGWAS directory ‚Äî tidyGWAS_paths","text":"list filepaths","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/tidyGWAS_paths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the folder structure and filepaths for downstreamGWAS directory ‚Äî tidyGWAS_paths","text":"","code":"if (FALSE) { # \\dontrun{  tidyGWAS_paths(\"gwas/height2022\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_clumping.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare tidyGWAS sumstats for PLINK clumping ‚Äî to_clumping","title":"Prepare tidyGWAS sumstats for PLINK clumping ‚Äî to_clumping","text":"Prepare tidyGWAS sumstats PLINK clumping","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_clumping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare tidyGWAS sumstats for PLINK clumping ‚Äî to_clumping","text":"","code":"to_clumping(hivestyle_path, output_dir)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_clumping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare tidyGWAS sumstats for PLINK clumping ‚Äî to_clumping","text":"hivestyle_path path tidyGWAS hivestyle dataset output_dir directory write sumstats.tsv","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_clumping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare tidyGWAS sumstats for PLINK clumping ‚Äî to_clumping","text":"","code":"if (FALSE) { # \\dontrun{ to_clumping(\"/path/to/hivestyle/dataset\", \"/path/to/output/dir\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ldsc.html","id":null,"dir":"Reference","previous_headings":"","what":"Export tidyGWAS format to LDSC format ‚Äî to_ldsc","title":"Export tidyGWAS format to LDSC format ‚Äî to_ldsc","text":"Export tidyGWAS format LDSC format","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ldsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export tidyGWAS format to LDSC format ‚Äî to_ldsc","text":"","code":"to_ldsc(parent_folder, use_effective_n = TRUE)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ldsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export tidyGWAS format to LDSC format ‚Äî to_ldsc","text":"parent_folder filepath tidyGWAS folder use_effective_n attempt made calculate effective N use N?","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ldsc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export tidyGWAS format to LDSC format ‚Äî to_ldsc","text":"","code":"if (FALSE) { # \\dontrun{ to_ldsc(\"my_sumstats/tidygwas/height2022\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ma.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert tidyGWAS to COJO .ma format ‚Äî to_ma","title":"Convert tidyGWAS to COJO .ma format ‚Äî to_ma","text":"Convert tidyGWAS COJO .ma format","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert tidyGWAS to COJO .ma format ‚Äî to_ma","text":"","code":"to_ma(parent_folder, out = NULL, use_effective_n = FALSE)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert tidyGWAS to COJO .ma format ‚Äî to_ma","text":"parent_folder filepath tidyGWAS folder output .ma file. Default value tidyGWAS_paths()[[\"ma_file]] use_effective_n N converted effective sample size? Requires CaseN ControlN column names","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_ma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert tidyGWAS to COJO .ma format ‚Äî to_ma","text":"","code":"if (FALSE) { # \\dontrun{ to_ma(\"/path/tidyGWAS_sumstats/a_sumstat\") } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_plink_clumping.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert tidyGWAS hivestyle partitioning to compatible format for plink clumping ‚Äî to_plink_clumping","title":"Convert tidyGWAS hivestyle partitioning to compatible format for plink clumping ‚Äî to_plink_clumping","text":"Convert tidyGWAS hivestyle partitioning compatible format plink clumping","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_plink_clumping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert tidyGWAS hivestyle partitioning to compatible format for plink clumping ‚Äî to_plink_clumping","text":"","code":"to_plink_clumping(parent_folder)"},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_plink_clumping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert tidyGWAS hivestyle partitioning to compatible format for plink clumping ‚Äî to_plink_clumping","text":"parent_folder filepath tidyGWAS folder","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_plink_clumping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert tidyGWAS hivestyle partitioning to compatible format for plink clumping ‚Äî to_plink_clumping","text":"writes file disk","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/to_plink_clumping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert tidyGWAS hivestyle partitioning to compatible format for plink clumping ‚Äî to_plink_clumping","text":"","code":"if (FALSE) { # \\dontrun{ paths <- tidyGWAS_paths(\"/my_sumstat/cleaned/\") to_plink_clumping(paths) } # }"},{"path":"http://arvidharder.com/downstreamGWAS/reference/with_container.html","id":null,"dir":"Reference","previous_headings":"","what":"Run arbitrary code inside a container ‚Äî with_container","title":"Run arbitrary code inside a container ‚Äî with_container","text":"Run arbitrary code inside container","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/with_container.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run arbitrary code inside a container ‚Äî with_container","text":"","code":"with_container(   code,   image,   workdir,   env = NULL,   setup_exists = FALSE,   R_code = FALSE )"},{"path":"http://arvidharder.com/downstreamGWAS/reference/with_container.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run arbitrary code inside a container ‚Äî with_container","text":"code code executed inside container. image container used? Used index params.yml workdir filepath directory. used working directory inside container env pass environmental variables container, format: \"KEY=VALUE\" Currently supports passing one variable setup_exists logical. TRUE, workdir, reference_dir container_dependecy paths assumed exist. bind paths code load apptainer/singularity written script R_code Running R Code using format: R -e \"$code\" challening due escaping quotes special characters. TRUE, code run using R -e \"$code\"","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/with_container.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run arbitrary code inside a container ‚Äî with_container","text":"character vector captured code","code":""},{"path":"http://arvidharder.com/downstreamGWAS/reference/with_container.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run arbitrary code inside a container ‚Äî with_container","text":"","code":"with_container(  code = \"echo hello\",  image = \"R\",  workdir = tempdir()  ) #> Warning: cannot open file '/home/runner/.config/downstreamGWAS/config.yml': No such file or directory #> Error in file(file, \"rt\", encoding = fileEncoding): cannot open the connection"},{"path":[]},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"goal","dir":"","previous_headings":"","what":"Goal","title":"downstreamGWAS Roadmap","text":"Make downstream GWAS analysis reproducible low-friction standardizing: input data contracts method-specific transformations containerized execution HPC reference data acquisition tracking roadmap formalizes core abstractions needed scale wrappers (run_clumping, run_sbayesrc, run_sbayess) stable method ecosystem coding agents can operate safely.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"design-principles","dir":"","previous_headings":"","what":"Design Principles","title":"downstreamGWAS Roadmap","text":"One canonical GWAS input: tidyGWAS format accepted raw input contract. Method modules, ad hoc wrappers: every method follows lifecycle interfaces. Reproducibility default: every run produces machine-readable provenance. Separation concerns: data prep, path resolution, execution, reference management independent layers. HPC-first, runtime-agnostic: support Apptainer/Singularity schedulers adapters. Concrete user-facing contract: every pipeline_* method behaves consistently inputs, outputs, script writing.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"function-contract-concrete","dir":"","previous_headings":"","what":"Function Contract (Concrete)","title":"downstreamGWAS Roadmap","text":"package-level contract method wrappers. Every pipeline_* method takes parent_dir. parent_dir points directory created tidyGWAS::tidyGWAS(). Every pipeline_* method accepts output_dir = NULL. output_dir NULL, output defaults : <parent_dir>/analysis/<method_name>/ output_dir set, method outputs written . standard pattern parameter sweeps. Every pipeline_* method supports write_script users can generate scripts without executing jobs immediately. Standard signatures (target): pipeline_clumping(parent_dir, output_dir = NULL, write_script = TRUE, execute = FALSE, ...) pipeline_sbayesrc(parent_dir, output_dir = NULL, write_script = TRUE, execute = FALSE, ...) pipeline_sbayess(parent_dir, output_dir = NULL, write_script = TRUE, execute = FALSE, ...) Notes: write_script = TRUE remains default HPC-first workflows. execute = FALSE keeps script generation execution clearly separated. Parameter sweeps always pass explicit output_dir values per run.","code":""},{"path":[]},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"id_1-dataset-contract","dir":"","previous_headings":"Core Abstractions","what":"1) Dataset Contract","title":"downstreamGWAS Roadmap","text":"Represents one trait summary-statistics dataset tidyGWAS format. Identity: dataset_id, trait name, source metadata Schema: required columns, optional columns, schema version Location: root folder + derived analysis subfolders Validation: explicit preflight checks method runs Planned API: dataset_open() dataset_validate() dataset_paths()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"id_2-method-spec","dir":"","previous_headings":"Core Abstractions","what":"2) Method Spec","title":"downstreamGWAS Roadmap","text":"Represents one analysis method (clumping, SBayesRC, SBayesS, LDSC, coloc, MR, etc.). method must implement standard contract: prepare: convert tidyGWAS method input (to_*) requirements: declare references, container, required columns build: generate executable commands/scripts parse: read method outputs standardized tables manifest: define run parameters output artifacts Planned API shape: method_prepare_<name>() method_run_<name>() method_parse_<name>() method_requirements_<name>()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"id_3-path-resolver","dir":"","previous_headings":"Core Abstractions","what":"3) Path Resolver","title":"downstreamGWAS Roadmap","text":"Single source truth host/container paths. Responsibilities: resolve analysis directories dataset root resolve reference paths registry/config map host paths container mounts deterministically handle quoting/safety shell commands removes hardcoded paths reduces breakage mixed path styles. Planned helper contract: returns output_dir provided otherwise returns fs::path(parent_dir, \"analysis\", method_name)","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"id_4-runtime-adapter","dir":"","previous_headings":"Core Abstractions","what":"4) Runtime Adapter","title":"downstreamGWAS Roadmap","text":"Encapsulates execution backend details. Responsibilities: container runtime abstraction (apptainer vs singularity) scheduler abstraction (start SLURM headers) dry-run script generation optional execution helpers (submit, run_local) keeps method logic independent infrastructure.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"id_5-reference-registry","dir":"","previous_headings":"Core Abstractions","what":"5) Reference Registry","title":"downstreamGWAS Roadmap","text":"Machine-readable catalog large reference assets (10-100GB+). Per reference entry: ref_id, version, source URL expected checksum(s) expected size ancestry/build tags local storage path Planned API: ref_list() ref_status() ref_download() ref_verify()","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"id_6-run-manifest--artifact-model","dir":"","previous_headings":"Core Abstractions","what":"6) Run Manifest + Artifact Model","title":"downstreamGWAS Roadmap","text":"Every method run writes structured manifest output directory. Manifest include: dataset id input paths method name version parameters used container image path/digest reference versions/checksums generated command/script output artifact list timestamps + status core interface reproducibility agent orchestration. run directory minimally contain: run.sh (write_script = TRUE) run_manifest.json status.json method outputs","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"id_7-orchestration-layer","dir":"","previous_headings":"Core Abstractions","what":"7) Orchestration Layer","title":"downstreamGWAS Roadmap","text":"Composable workflow planner across multiple methods traits. Planned API: plan_analysis() creates executable plan objects (DAG-ready) run_analysis() executes plan steps status updates read_status() reports current/finished/failed states allows agents reason analysis state instead parsing ad hoc files.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"target-repository-structure","dir":"","previous_headings":"","what":"Target Repository Structure","title":"downstreamGWAS Roadmap","text":"Proposed additions current layout: inst/extdata/references.yml (reference registry) R/methods-*.R (method specs wrappers) R/runtime-*.R (runtime scheduler adapters) R/refs-*.R (reference manager) R/manifests.R (run manifest utilities) Standard output per method: analysis/<method>/run.sh analysis/<method>/run_manifest.json analysis/<method>/status.json analysis/<method>/results/*","code":""},{"path":[]},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"phase-0-stabilize-existing-core-immediate","dir":"","previous_headings":"Phased Delivery","what":"Phase 0: Stabilize Existing Core (Immediate)","title":"downstreamGWAS Roadmap","text":"Focus methods: clumping, SBayesRC, SBayesS. Deliverables: fix existing filepath/runtime inconsistencies remove hardcoded reference paths wrappers enforce parent_dir + default/custom output_dir behavior consistently standardize write_script behavior return values across core methods add strict preflight checks required files/columns add script snapshot tests generated commands","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"phase-1-method-spec-standardization","dir":"","previous_headings":"Phased Delivery","what":"Phase 1: Method Spec Standardization","title":"downstreamGWAS Roadmap","text":"Deliverables: formal method_* contract refactor clumping/SBayesRC/SBayesS contract standardized output folder + manifest per method","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"phase-2-reference-data-product","dir":"","previous_headings":"Phased Delivery","what":"Phase 2: Reference Data Product","title":"downstreamGWAS Roadmap","text":"Deliverables: implement reference registry verification download/verify/status commands pin references version/checksum run manifests","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"phase-3-orchestration--agent-interface","dir":"","previous_headings":"Phased Delivery","what":"Phase 3: Orchestration + Agent Interface","title":"downstreamGWAS Roadmap","text":"Deliverables: plan/run/status APIs dry-run resumable execution machine-readable error categories step-level logs","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"phase-4-method-expansion","dir":"","previous_headings":"Phased Delivery","what":"Phase 4: Method Expansion","title":"downstreamGWAS Roadmap","text":"Deliverables: migrate/add LDSC, coloc, MR, mBAT-combo, others ensure methods emit standardized manifests integration tests across multi-method pipelines","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"future-proofing-requirements","dir":"","previous_headings":"","what":"Future-Proofing Requirements","title":"downstreamGWAS Roadmap","text":"abstractions explicitly support: multiple ancestries genome builds multiple trait datasets one analysis plan reference mirroring offline HPC environments resumability partial failures deterministic reruns years later incremental addition new methods minimal plumbing changes","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"apptainer--filepaths-plan-critical-path","dir":"","previous_headings":"","what":"Apptainer + Filepaths Plan (Critical Path)","title":"downstreamGWAS Roadmap","text":"critical subsystem every method depends .","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"current-state-summary","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Current State (Summary)","title":"downstreamGWAS Roadmap","text":"Reference/container relative paths shipped package inst/extdata/params.yml. Local machine-specific settings stored user config (~/.config/downstreamGWAS/config.yml). Methods compose host/container paths files. split directionally correct, needs stricter contracts versioning.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"recommendation-on-shipping-filepaths-in-the-r-package","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Recommendation on Shipping Filepaths in the R Package","title":"downstreamGWAS Roadmap","text":"Keep shipping defaults R package, treat source truth. Use two-layer model: canonical IDs methods, references, containers default relative paths default runtime assumptions actual storage locations HPC/container runtime differences local mirror paths site-specific naming Rationale: Shipping defaults gives reproducible bootstrap behavior. Local overrides mandatory real HPC environments. prevents hardcoding site-specific assumptions package releases.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"filepath-contract","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Filepath Contract","title":"downstreamGWAS Roadmap","text":"method code use resolved paths one resolver API. Required resolver outputs: host_workdir host_reference_root host_container_path container_workdir (default /mnt) container_reference_root (default /src) resolved_reference_files (per method) resolved_output_dir method manually concatenate path strings resolution step.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"runtime-contract-apptainersingularity","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Runtime Contract (Apptainer/Singularity)","title":"downstreamGWAS Roadmap","text":"Define one runtime adapter emits execution commands. Adapter responsibilities: choose runtime binary config (apptainer singularity) emit bind mounts resolved paths support env vars (OMP_NUM_THREADS, etc.) support command R -e execution safely return rendered command lines manifests/tests Method wrappers never write raw apptainer exec lines directly. Batch scheduler focus: initial batch scheduler target SLURM (sbatch) scheduler API stay modular additional backends (e.g.¬†PBS/LSF) can added without changing method-level pipeline code pipelines accept schedule object (default NULL) instead embedding scheduler flags every method signature","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"registry-and-versioning","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Registry and Versioning","title":"downstreamGWAS Roadmap","text":"Create explicit registries stable IDs: containers.yml (image IDs, default filenames, optional digest metadata) references.yml (reference IDs, versions, expected size, optional checksums, build/ancestry tags) methods.yml (method -> required container IDs + reference IDs) Package can ship defaults inst/extdata/; local overrides can live config directory.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"override--merge-rules","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Override + Merge Rules","title":"downstreamGWAS Roadmap","text":"Deterministic precedence: function arguments (highest) local/site registry overrides package defaults (lowest) Every run manifest record layer provided resolved path.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"validation-requirements","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Validation Requirements","title":"downstreamGWAS Roadmap","text":"script creation: validate runtime binary availability validate container file exists readable validate required reference files exist (optionally match expected size configured) validate output dir writable fail fast machine-readable errors Checksum verification explicit -demand operation (ref_verify()), part default per-setup per-run validation.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"migration-plan-from-current-paramsyml-setup","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Migration Plan from Current params.yml Setup","title":"downstreamGWAS Roadmap","text":"Keep params.yml working backward compatibility. Introduce new resolver API internal adapters first. Move methods (clumping, sbayesrc, sbayess) resolver-path usage. Add deprecation warnings direct access patterns bypass resolver. Introduce containers.yml + references.yml resolver stable.","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"testing-plan-for-this-layer","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Testing Plan for This Layer","title":"downstreamGWAS Roadmap","text":"unit tests path resolution precedence rules unit tests runtime command rendering (apptainer singularity) snapshot tests rendered scripts core methods fixture tests missing refs/containers clear error messages","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"phase-0-deliverables-expanded","dir":"","previous_headings":"Apptainer + Filepaths Plan (Critical Path)","what":"Phase 0 Deliverables (Expanded)","title":"downstreamGWAS Roadmap","text":"implement resolve_runtime() resolve_method_paths() update with_container() runtime-agnostic command generation remove hardcoded runtime calls method wrappers enforce default/custom output_dir shared resolver helper include resolved runtime/path block run_manifest.json","code":""},{"path":"http://arvidharder.com/downstreamGWAS/roadmap.html","id":"success-criteria","dir":"","previous_headings":"","what":"Success Criteria","title":"downstreamGWAS Roadmap","text":"Adding new method requires method-specific code registry entries. runs reproducible manifests without manual reconstruction. Analysts agents can discover missing references required setup programmatically. Core workflows (clumping, sbayesrc, sbayess) stable tested end--end script generation level. pipeline_* methods share concrete interface (parent_dir, output_dir, write_script, optional execute).","code":""}]
